# Introduction to Transformers - IOAI 2025

This repository contains materials for the workshop designed for participants of the International Olympiad in Artificial Intelligence (IOAI).


## Workshop Structure

### Part 1: Transformer Architecture Deep Dive
- Learn the building blocks of Transformer models, including embeddings, encoders, and position encodings.
- Understand how input text is processed through the model.
  
### Part 2: Attention Mechanism and Multi-Head Attention
- Inspect intermediate states like attention weights and hidden layers.

_Parts 1 and 2 are mostly focused on conceptual understanding, visualizations, and internal mechanics._

### Part 3: Embeddings and Weight Manipulation

### Part 4: Cross-Lingual Adaptation


## Notebooks

Before starting the workshop, **make a personal copy of the notebook**. You will work in your own version during the session. To do so, go to the **_File_** menu in Colab and selecting _**Save a copy in Drive**_.

Workshop: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1yQXBNEiga9kLd7ZMvBtJsF5GEkTTpQvm?usp=sharing)

Solution: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1NezmgEXVCRFgjJErIhfBolr1XJ0QeOOI?usp=sharing)


## References
